# Introduction

> Welcome to the Nano-GPT.com API

## Overview

The NanoGPT API allows you to generate text, images and video using any AI model available. Our implementation for text generation generally matches the OpenAI standards. We also support verifiably private TEE (Trusted Execution Environment) models, allowing for confidential computations.

<Note>
  All examples in this documentation also work on our alternative domains. Just replace the base URL `https://nano-gpt.com` with your preferred domain: [ai.bitcoin.com](https://ai.bitcoin.com), [bcashgpt.com](https://bcashgpt.com), or [cake.nano-gpt.com](https://cake.nano-gpt.com). Only the base URL changes; endpoints and request formats remain the same.
</Note>

## Chat Completion example

Here's a simple python example using our OpenAI-compatible chat completions endpoint:

```python  theme={null}
import requests
import json

BASE_URL = "https://nano-gpt.com/api/v1"
API_KEY = "YOUR_API_KEY"  # Replace with your API key

headers = {
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json",
    "Accept": "text/event-stream"  # Required for SSE streaming
}

def stream_chat_completion(messages, model="chatgpt-4o-latest"):
    """
    Send a streaming chat completion request using the OpenAI-compatible endpoint.
    """
    data = {
        "model": model,
        "messages": messages,
        "stream": True  # Enable streaming
    }

    response = requests.post(
        f"{BASE_URL}/chat/completions",
        headers=headers,
        json=data,
        stream=True
    )

    if response.status_code != 200:
        raise Exception(f"Error: {response.status_code}")

    for line in response.iter_lines():
        if line:
            line = line.decode('utf-8')
            if line.startswith('data: '):
                line = line[6:]
            if line == '[DONE]':
                break
            try:
                chunk = json.loads(line)
                if chunk['choices'][0]['delta'].get('content'):
                    yield chunk['choices'][0]['delta']['content']
            except json.JSONDecodeError:
                continue

# Example usage
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Please explain the concept of artificial intelligence."}
]

try:
    print("Assistant's Response:")
    for content_chunk in stream_chat_completion(messages):
        print(content_chunk, end='', flush=True)
    print("")
except Exception as e:
    print(f"Error: {str(e)}")
```

## Quick Start

The quickest way to get started with our API is to explore our [Endpoint Examples](/api-reference/endpoint/chat-completion). Each endpoint page provides comprehensive documentation with request/response formats and example code. The [Chat Completion](/api-reference/endpoint/chat-completion) endpoint is a great starting point for text generation.

## Documentation Sections

For detailed documentation on each feature, please refer to the following sections:

* [Text Generation](/api-reference/text-generation) - Complete guide to text generation APIs including OpenAI-compatible endpoints and legacy options
* [Image Generation](/api-reference/image-generation) - Learn how to generate images using various models like Recraft, Flux, and Stable Diffusion.
* [Video Generation](/api-reference/video-generation) - Create high-quality videos with our video generation API
* [TEE Model Verification](/api-reference/tee-verification) - Verify attestation and signatures for TEE-backed models.

## What's New

* Wavespeed video models now accept direct `imageUrl` inputs, so you can reference publicly hosted images without converting them to base64 first.


---

> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.nano-gpt.com/llms.txt