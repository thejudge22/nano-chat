# Quickstart

> Start querying any model within 2 minutes.

## Get your API key

Generate an API key on our [API page](https://nano-gpt.com/api).

## Add Balance

If you haven't deposited yet, add some funds to [your balance](https://nano-gpt.com/balance). Minimum deposit is just \$1, or \$0.10 when using crypto.

### API usage examples

<AccordionGroup>
  <Accordion icon="message-bot" title="Text Generation">
    Here's a simple example using our OpenAI-compatible chat completions endpoint:

    ```python  theme={null}
    import requests
    import json

    BASE_URL = "https://nano-gpt.com/api/v1"
    API_KEY = "YOUR_API_KEY"  # Replace with your API key

    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json",
        "Accept": "text/event-stream"  # Required for SSE streaming
    }

    def stream_chat_completion(messages, model="chatgpt-4o-latest"):
        """
        Send a streaming chat completion request using the OpenAI-compatible endpoint.
        """
        data = {
            "model": model,
            "messages": messages,
            "stream": True  # Enable streaming
        }

        response = requests.post(
            f"{BASE_URL}/chat/completions",
            headers=headers,
            json=data,
            stream=True
        )

        if response.status_code != 200:
            raise Exception(f"Error: {response.status_code}")

        for line in response.iter_lines():
            if line:
                line = line.decode('utf-8')
                if line.startswith('data: '):
                    line = line[6:]
                if line == '[DONE]':
                    break
                try:
                    chunk = json.loads(line)
                    if chunk['choices'][0]['delta'].get('content'):
                        yield chunk['choices'][0]['delta']['content']
                except json.JSONDecodeError:
                    continue

    # Example usage
    messages = [
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Please explain the concept of artificial intelligence."}
    ]

    try:
        print("Assistant's Response:")
        for content_chunk in stream_chat_completion(messages):
            print(content_chunk, end='', flush=True)
        print("")
    except Exception as e:
        print(f"Error: {str(e)}")
    ```

    For more detailed examples and other text generation endpoints, check out our [Text Generation Guide](/api-reference/text-generation).
  </Accordion>

  <Accordion icon="image" title="Image Generation">
    #### OpenAI-Compatible Endpoint (v1/images/generations)

    You can also generate images using our OpenAI-compatible endpoint:

    ```bash  theme={null}
    curl https://nano-gpt.com/v1/images/generations \
      -H "Authorization: Bearer YOUR_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "hidream",
        "prompt": "A serene landscape at sunset",
        "n": 1,
        "size": "1024x1024"
      }'
    ```

    Here's an example using the OpenAI-compatible endpoint in Python:

    ```python  theme={null}
    import base64
    import requests

    API_KEY = "YOUR_API_KEY"

    def generate_image(prompt, model="hidream", size="1024x1024"):
        response = requests.post(
            "https://nano-gpt.com/v1/images/generations",
            headers={
                "Authorization": f"Bearer {API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": model,
                "prompt": prompt,
                "n": 1,
                "size": size,
                "response_format": "b64_json"
            }
        )
        response.raise_for_status()
        return response.json()

    # Example usage
    prompt = "A serene landscape with mountains and a lake at sunset, digital art style"
    result = generate_image(prompt)

    image_bytes = base64.b64decode(result["data"][0]["b64_json"])
    with open("generated_image.png", "wb") as f:
        f.write(image_bytes)

    print("Image generated successfully!")
    print("Image saved as 'generated_image.png'")
    ```

    For more detailed examples and other image generation options, check out our [Image Generation Guide](/api-reference/image-generation).
  </Accordion>

  <Accordion icon="globe" title="Web Search">
    Enable real-time web search for any model by adding suffixes to the model name:

    ```python  theme={null}
    import requests
    import json

    BASE_URL = "https://nano-gpt.com/api/v1"
    API_KEY = "YOUR_API_KEY"

    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }

    # Standard web search ($0.006 per request)
    data = {
        "model": "chatgpt-4o-latest:online",
        "messages": [
            {"role": "user", "content": "What are the latest AI announcements this week?"}
        ],
        "stream": False
    }

    response = requests.post(
        f"{BASE_URL}/chat/completions",
        headers=headers,
        json=data
    )

    print("Response:", response.json()['choices'][0]['message']['content'])

    # Deep web search for comprehensive research ($0.06 per request)
    deep_data = {
        "model": "claude-3-5-sonnet-20241022:online/linkup-deep",
        "messages": [
            {"role": "user", "content": "Provide a detailed analysis of recent breakthroughs in quantum computing"}
        ]
    }

    deep_response = requests.post(
        f"{BASE_URL}/chat/completions",
        headers=headers,
        json=deep_data
    )
    ```

    Web search works with all models and provides:

    * Access to real-time information (updated less than a minute ago)
    * 10x improvement in factuality
    * Standard search: 10 results quickly
    * Deep search: Iterative searching for comprehensive information

    For more advanced web search capabilities including structured output, domain filtering, and date filtering, see the [Web Search API](/api-reference/endpoint/web-search).

    Check out our [Chat Completion Guide](/api-reference/endpoint/chat-completion) for more examples.
  </Accordion>

  <Accordion icon="shield-check" title="TEE Model Verification">
    NanoGPT supports TEE-backed models for verifiable privacy. You can fetch attestation reports and signatures for chat completions made with these models.

    Here's how to fetch an attestation report:

    ```bash  theme={null}
    curl "https://nano-gpt.com/api/v1/tee/attestation?model=TEE/hermes-3-llama-3.1-70b" \
      -H "Authorization: Bearer YOUR_API_KEY"
    ```

    After making a chat request with a TEE model, you can get its signature:

    ```bash  theme={null}
    # First, make a chat request (see Text Generation accordion or TEE Verification guide)
    # Then, use the request_id from the chat response:
    curl "https://nano-gpt.com/api/v1/tee/signature/YOUR_CHAT_REQUEST_ID?model=TEE/hermes-3-llama-3.1-70b&signing_algo=ecdsa" \
      -H "Authorization: Bearer YOUR_API_KEY"
    ```

    For a complete Python example and more details, see the [TEE Verification Guide](/api-reference/tee-verification).
  </Accordion>
</AccordionGroup>


---

> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.nano-gpt.com/llms.txt